{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Geophysique CEA\n",
    "# LIBRAIRIES Python\n",
    "# Pyton 2.7 Numpy 1.14.5 Matplotlib 2.2.3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import seaborn as sns\n",
    "\n",
    "# For model construction and data processing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hasso\\\\PythonWithAnaconda\\\\GEO_CEA\\\\Article'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MM\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading training HR\n",
    "data_train = np.loadtxt('./DATA/dataHR20K.DAT')\n",
    "X = np.copy(data_train[:,0:3])\n",
    "\n",
    "# Data and processing\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "\n",
    "# Scaling\n",
    "X_Train_M13 = scaler.transform(X) \n",
    "Y_Train_M13 = np.copy(data_train[:,3])\n",
    "\n",
    "# Testing data\n",
    "## Test M13\n",
    "data_test_M13 = np.loadtxt('./DATA/dataVALID_interHR.DAT')\n",
    "X_1 = np.copy(data_test_M13[:,0:3])\n",
    "X_test_M13 = scaler.transform(X_1)   \n",
    "Y_test_M13 = np.copy(data_test_M13[:,3])\n",
    "\n",
    "## Test L\n",
    "data_test_M13_L = np.loadtxt('./DATA/dataVALIDL_interLR.DAT')\n",
    "X_L = np.copy(data_test_M13_L[:,0:3])\n",
    "X_test_M13_L = scaler.transform(X_L)\n",
    "Y_test_M13_L = np.copy(data_test_M13_L[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup and Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up initial model\n",
    "tree_mod = tree.DecisionTreeRegressor(min_samples_leaf=1)\n",
    "knn = KNeighborsRegressor(n_neighbors=2)\n",
    "Bag = BaggingRegressor(base_estimator=tree_mod)\n",
    "RF = RandomForestRegressor(min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, estimator=KNeighborsRegressor(n_neighbors=2),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19])})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation \n",
    "# ================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "# ================================================================\n",
    "\n",
    "# param_grid_rf = {\"n_estimators\" : np.arange(10,151,10)}\n",
    "param_grid_knn = {\"n_neighbors\" : np.arange(1,20)}\n",
    "\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "# ================================================\n",
    "\n",
    "# bag_cv = GridSearchCV(Bag, param_grid_rf, cv=20)\n",
    "# rf_cv = GridSearchCV(RF, param_grid_rf, cv=20)\n",
    "knn_cv = GridSearchCV(knn, param_grid_knn, cv=20)\n",
    "\n",
    "#fit model to data\n",
    "# ================\n",
    "\n",
    "# bag_cv.fit(X_Train_M13, Y_Train_M13)\n",
    "# rf_cv.fit(X_Train_M13, Y_Train_M13)\n",
    "knn_cv.fit(X_Train_M13, Y_Train_M13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best parameters\n",
    "# ===============\n",
    "# bag_cv.best_params_\n",
    "# rf_cv.best_params_\n",
    "\n",
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Error of KNN on M13 data:0.010126926977687639\n",
      "Testing Error of KNN on M13_L data:0.36371843036978757\n"
     ]
    }
   ],
   "source": [
    "# Training and prediction\n",
    "# =======================\n",
    "\n",
    "## Optimal model\n",
    "\n",
    "# Bag = BaggingRegressor(n_estimators = bag_cv.best_params_[\"n_estimators\"], base_estimator=tree_mod)\n",
    "# RF = RandomForestRegressor(n_estimators = rf_cv.best_params_[\"n_estimators\"], min_samples_leaf=1)\n",
    "knn = KNeighborsRegressor(n_neighbors = knn_cv.best_params_['n_neighbors'])\n",
    "\n",
    "## Training and prediction\n",
    "\n",
    "### Tree \n",
    "# treefit = tree_mod.fit(X_Train_M13,Y_Train_M13)\n",
    "# pred_train_tr = treefit.predict(X_Train_M13)\n",
    "# pred_test_tr = treefit.predict(X_test_M13)\n",
    "# pred_test_tr_L = treefit.predict(X_test_M13_L)\n",
    "\n",
    "### Bagging\n",
    "# Bagfit = Bag.fit(X_Train_M13, Y_Train_M13)\n",
    "# pred_train_bag = Bagfit.predict(X_Train_M13)\n",
    "# pred_test_bag = Bagfit.predict(X_test_M13)\n",
    "# pred_test_bag_L = Bagfit.predict(X_test_M13_L)\n",
    "\n",
    "### Random Forest\n",
    "# RFfit = RF.fit(X_Train_M13, X_Train_M13)\n",
    "# pred_train_rf = RFfit.predict(X_Train_M13)\n",
    "# pred_test_rf = RFfit.predict(X_test_M13)\n",
    "# pred_test_rf_L = RFfit.predict(X_test_M13_L)\n",
    "\n",
    "### KNN\n",
    "\n",
    "KNNfit = knn.fit(X_Train_M13, Y_Train_M13)\n",
    "pred_train_knn = KNNfit.predict(X_Train_M13)\n",
    "pred_test_knn = KNNfit.predict(X_test_M13)\n",
    "pred_test_knn_L = KNNfit.predict(X_test_M13_L)\n",
    "\n",
    "#print('Testing Error of Tree on M13 data:' + str(metrics.mean_absolute_error(pred_test_tr, Y_test_M13, squared=True)))\n",
    "#print('Testing Error of Tree on M13_L data:' + str(metrics.mean_absolute_error(pred_test_tr_L, Y_test_M13_L, squared=True)))\n",
    "#print('Testing Error of Bag M13 data:' + str(metrics.mean_absolute_error(pred_test_bag, Y_test_M13, squared=True)))\n",
    "#print('Testing Error of Bag M13_L data:' + str(metrics.mean_absolute_error(pred_test_bag_L, Y_test_M13_L, squared=True)))\n",
    "#print('Testing Error of RF on M13 data:' + str(metrics.mean_absolute_error(pred_test_rf, Y_test_M13, squared=True)))\n",
    "#print('Testing Error of RF on M13_L data:' + str(metrics.mean_absolute_error(pred_test_rf_L, Y_test_M13_L, squared=True)))\n",
    "print('Testing Error of KNN on M13 data:' + str(metrics.mean_absolute_error(pred_test_knn, Y_test_M13)))\n",
    "print('Testing Error of KNN on M13_L data:' + str(metrics.mean_absolute_error(pred_test_knn_L, Y_test_M13_L)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
